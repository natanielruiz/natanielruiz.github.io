<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Nataniel Ruiz</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: 20px;
        }
        .header-info {
            flex: 1;
        }
        .profile-photo {
            width: 150px;
            height: 150px;
            border-radius: 50%;
        }
        h1 {
            font-size: 28px;
            margin: 0 0 10px 0;
        }
        h2 {
            font-size: 22px;
            margin: 30px 0 15px 0;
            border-bottom: 1px solid #ccc;
            padding-bottom: 5px;
        }
        h3 {
            font-size: 18px;
            margin: 0 0 10px 0;
        }
        p {
            margin: 0 0 10px 0;
        }
        a {
            color: #0000EE;
            text-decoration: none;
        }
        .links a {
            margin-right: 10px;
        }
        .publication {
            display: flex;
            margin-bottom: 20px;
        }
        .publication-info {
            flex: 1;
        }
        .publication-image {
            width: 150px;
            height: auto;
            margin-left: 20px;
        }
    </style>
</head>
<body>
    <div class="header">
        <div class="header-info">
            <h1>NATANIEL RUIZ</h1>
            <p>Research Scientist, Google</p>
            <div class="links">
                <a href="mailto:nruiz9@bu.edu">Email</a> /
                <a href="docs/nataniel_cv_long.pdf">CV</a> /
                <a href="https://scholar.google.fr/citations?user=CiOmcSIAAAAJ&hl=en">Google Scholar</a> /
                <a href="https://github.com/natanielruiz">GitHub</a> /
                <a href="https://www.linkedin.com/in/nataniel-ruiz/">LinkedIn</a>
            </div>
        </div>
        <img src="figs/headshot_circle.png" alt="Nataniel Ruiz" class="profile-photo">
    </div>

    <h2>ABOUT ME</h2>
    <p>I am a Research Scientist at Google. Previously I completed my PhD at <a href="http://www.bu.edu/">Boston University</a>, advised by Professor and Dean of the College of Arts and Sciences <a href="http://www.cs.bu.edu/fac/sclaroff/">Stan Sclaroff</a>. My primary research focus is computer vision and machine learning.</p>
    
    <p>I interned at Amazon working with <a href="https://scholar.google.com/citations?user=Wx62iOsAAAAJ&hl=en">Javier Romero</a>, <a href="https://sites.google.com/site/bolkartt/">Timo Bolkart</a>, <a href="https://www.cs.umd.edu/~lin/">Ming C. Lin</a> and <a href="https://scholar.google.com/citations?user=hY3uN8oAAAAJ&hl=en">Raja Bala</a> during the Summer of 2021. I interned at <a href="https://machinelearning.apple.com/">Apple AI Research</a> during the 2019 and 2020 Summers where I worked with <a href="https://scholar.google.com/citations?user=DNrQd3IAAAAJ&hl=en">Dr. Barry-John Theobald</a> and <a href="https://scholar.google.com/citations?user=p4w7a_kAAAAJ&hl=en">Dr. Nicholas Apostoloff</a>. In 2018 I was a Spring/Summer intern at the <a href="http://www.nec-labs.com/research-departments/media-analytics/media-analytics-home">NEC-Labs Media Analytics Department</a>, where I worked with <a href="http://www.nec-labs.com/~manu/">Prof. Manmohan Chandraker</a> and <a href="http://www.nec-labs.com/samuel-schulter">Dr. Samuel Schulter</a>.</p>

    <h2>PUBLICATIONS</h2>
    <div class="publication">
        <div class="publication-info">
            <h3><a href="https://dreambooth.github.io">DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</a></h3>
            <p><strong>N. Ruiz</strong>, Y. Li, V. Jampani, Y. Pritch, M. Rubinstein, K. Aberman</p>
            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2023</p>
            <p><strong>(Best Student Paper Honorable Mention Award - 0.25% award rate)</strong></p>
            <p>
                <a href="https://dreambooth.github.io">Website</a> /
                <a href="https://en.wikipedia.org/wiki/DreamBooth">Wikipedia</a> /
                <a href="https://www.youtube.com/watch?v=W4Mcuh38wyM">Corridor Crew demo video</a> /
                <a href="https://twitter.com/natanielruizg/status/1563166568195821569?s=20&t=vAnQmQb7iYVoKTzgblFxYg">Announcement tweet</a>
            </p>
        </div>
        <img src="figs/dreambooth.png" alt="DreamBooth" class="publication-image">
    </div>

    <div class="publication">
        <div class="publication-info">
            <h3><a href="https://arxiv.org/abs/2106.04569">Simulated Adversarial Testing of Face Recognition Models</a></h3>
            <p><strong>N. Ruiz</strong>, A. Kortylewski, W. Qiu, Cihang Xie, Sarah Adel Bargal, Alan Yuille, S. Sclaroff</p>
            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2022</p>
            <p><a href="https://arxiv.org/pdf/2106.04569.pdf">PDF</a></p>
        </div>
        <img src="figs/adv_test_sim.png" alt="Simulated Adversarial Testing" class="publication-image">
    </div>

    <div class="publication">
        <div class="publication-info">
            <h3><a href="https://arxiv.org/abs/2012.05225">MorphGAN: One-Shot Face Synthesis GAN for Detecting Recognition Bias</a></h3>
            <p><strong>N. Ruiz</strong>, B. J. Theobald, A. Ranjan, A. H. Abdelaziz, N. Apostoloff</p>
            <p>British Machine Vision Conference (BMVC), 2021</p>
            <p><a href="https://arxiv.org/pdf/2012.05225.pdf">PDF</a></p>
        </div>
        <img src="figs/morphgan.gif" alt="MorphGAN" class="publication-image">
    </div>

    <div class="publication">
        <div class="publication-info">
            <h3><a href="https://arxiv.org/abs/2002.05242">Leveraging Affect Transfer Learning for Behavior Prediction in an Intelligent Tutoring System</a></h3>
            <p><strong>N. Ruiz</strong>, H. Yu, D. Allessio, M. Jalal, Thomas Murray, J. Magee, J. Whitehill, V. Ablavsky, I. Arroyo, B. Woolf, S. Sclaroff, M. Betke</p>
            <p>IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2021</p>
            <p>IEEE Transactions on Biometrics, Identity and Behavior (T-BIOM), 2022</p>
            <p><strong>(Selected for Oral Presentation and Best Poster Award - 4% award rate)</strong></p>
            <p><a href="https://arxiv.org/pdf/2002.05242.pdf">PDF</a> / <a href="https://ieeexplore.ieee.org/abstract/document/9906410">Journal paper</a></p>
        </div>
        <img src="figs/img_leveraging.png" alt="Leveraging Affect Transfer Learning" class="publication-image">
    </div>

    <div class="publication">
        <div class="publication-info">
            <h3><a href="https://arxiv.org/abs/2003.01279">Disrupting DeepFakes: Adversarial Attacks Against Conditional Image Translation Networks and Facial Manipulation Systems</a></h3>
            <p><strong>N. Ruiz</strong>, S. Bargal, S. Sclaroff</p>
            <p>CVPR Workshop on Adversarial Machine Learning in Computer Vision and ECCV Workshop on Advances in Image Manipulation, 2020</p>
            <p>
                <a href="https://arxiv.org/pdf/2003.01279.pdf">PDF</a> /
                <a href="https://twimlai.com/twiml-talk-375-disrupting-deepfakes-adversarial-attacks-against-conditional-image-translation-networks-with-nataniel-ruiz/">Podcast</a> /
                <a href="https://github.com/natanielruiz/disrupting-deepfakes">Code</a>
            </p>
        </div>
        <img src="figs/img_disrupt.png" alt="Disrupting DeepFakes" class="publication-image">
    </div>

    <div class="publication">
        <div class="publication-info">
            <h3><a href="https://arxiv.org/abs/2003.02501">Detecting Attended Visual Targets in Video</a></h3>
            <p>E. Chong, Y. Wang, <strong>N. Ruiz</strong>, J.M. Rehg</p>
            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2020</p>
            <p><a href="https://arxiv.org/pdf/2003.02501.pdf">PDF</a> / <a href="https://github.com/ejcgt/attention-target-detection">Code</a></p>
        </div>
        <img src="figs/img_visual_target_video.png" alt="Detecting Attended Visual Targets" class="publication-image">
    </div>

    <div class="publication">
        <div class="publication-info">
            <h3><a href="https://arxiv.org/abs/1810.02513">Learning To Simulate</a></h3>
            <p><strong>N. Ruiz</strong>, S. Schulter, M. Chandraker</p>
            <p>International Conference on Learning Representations (ICLR), 2019</p>
            <p><a href="https://arxiv.org/pdf/1810.02513.pdf">PDF</a> / <a href="docs/lts_poster.pdf">Poster</a></p>
        </div>
        <img src="figs/lts_sim.png" alt="Learning To Simulate" class="publication-image">
    </div>

    <div class="publication">
        <div class="publication-info">
            <h3><a href="http://openaccess.thecvf.com/content_ECCV_2018/html/Eunji_Chong_Connecting_Gaze_Scene_ECCV_2018_paper.html">Connecting Gaze, Scene, and Attention: Generalized Attention Estimation via Joint Modeling of Gaze and Scene Saliency</a></h3>
            <p>E. Chong, <strong>N. Ruiz</strong>, Y. Wang, Y. Zhang, A. Rozga, J.M. Rehg</p>
            <p>European Conference on Computer Vision (ECCV), 2018</p>
            <p>
                <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Eunji_Chong_Connecting_Gaze_Scene_ECCV_2018_paper.pdf">PDF</a> /
                <a href="docs/argos_poster.pdf">Poster</a> /
                <a href="docs/Chong_2018_ECCV.bib">Bibtex</a>
            </p>
        </div>
        <img src="figs/gaze.png" alt="Connecting Gaze, Scene, and Attention" class="publication-image">
    </div>

    <div class="publication">
        <div class="publication-info">
            <h3><a href="http://openaccess.thecvf.com/content_cvpr_2018_workshops/w41/html/Ruiz_Fine-Grained_Head_Pose_CVPR_2018_paper.html">Fine-Grained Head Pose Estimation Without Keypoints</a></h3>
            <p><strong>N. Ruiz</strong>, E. Chong, J.M. Rehg</p>
            <p>Conference on Computer Vision and Pattern Recognition Workshop (CVPRW), 2018 <strong>(Oral Presentation)</strong></p>
            <p>
                <a href="http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w41/Ruiz_Fine-Grained_Head_Pose_CVPR_2018_paper.pdf">PDF</a> /
                <a href="https://github.com/natanielruiz/deep-head-pose">Code</a> /
                <a href="docs/hopenet_poster.pdf">Poster</a> /
                <a href="docs/ruiz2017fine.bib">Bibtex</a>
            </p>
        </div>
        <img src="figs/deep-head-pose.png" alt="Fine-Grained Head Pose Estimation" class="publication-image">
    </div>

    <div class="publication">
        <div class="publication-info">
            <h3><a href="https://arxiv.org/abs/1809.08381">Learning to Localize and Align Fine-Grained Actions to Sparse Instructions</a></h3>
            <p>M. Hahn, <strong>N. Ruiz</strong>, J.B. Alayrac, I. Laptev, J.M. Rehg</p>
            <p>arXiv, 2018</p>
            <p><a href="https://arxiv.org/pdf/1809.08381.pdf">PDF</a></p></div>
            <img src="figs/localize-and-align.png" alt="Learning to Localize and Align Fine-Grained Actions" class="publication-image">
        </div>
    
        <div class="publication">
            <div class="publication-info">
                <h3><a href="https://dl.acm.org/citation.cfm?id=3131902">Detecting Gaze Towards Eyes in Natural Social Interactions and Its Use in Child Assessment</a></h3>
                <p>E. Chong, K. Chanda, Z. Ye, A. Southerland, <strong>N. Ruiz</strong>, R.M. Jones, A. Rozga, J.M. Rehg</p>
                <p>UbiComp and Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT), 2017</p>
                <p><strong>(Selected for Oral Presentation and Distinguished Paper Award - 3% award rate)</strong></p>
                <p>
                    <a href="https://dl.acm.org/doi/pdf/10.1145/3131902">PDF</a> /
                    <a href="docs/chong2017imwut.bib">Bibtex</a>
                </p>
            </div>
            <img src="figs/eye-contact.png" alt="Detecting Gaze Towards Eyes" class="publication-image">
        </div>
    
        <div class="publication">
            <div class="publication-info">
                <h3><a href="https://arxiv.org/abs/1708.04370">Dockerface: an Easy to Install and Use Faster R-CNN Face Detector in a Docker Container</a></h3>
                <p><strong>N. Ruiz</strong>, J.M. Rehg</p>
                <p>arXiv, 2017</p>
                <p>
                    <a href="https://arxiv.org/pdf/1708.04370.pdf">PDF</a> /
                    <a href="https://github.com/natanielruiz/dockerface">Code</a> /
                    <a href="docs/ruiz2017dockerface.bib">Bibtex</a>
                </p>
            </div>
            <img src="figs/dockerface.jpg" alt="Dockerface" class="publication-image">
        </div>
    
        <h2>PROJECTS</h2>
        <div class="publication">
            <div class="publication-info">
                <h3><a href="https://github.com/natanielruiz/android-yolo">android-yolo</a></h3>
                <p><strong>N. Ruiz</strong></p>
                <p>Real-time object detection on Android using the YOLO network with TensorFlow.</p>
                <p>
                    <a href="https://github.com/natanielruiz/android-yolo">GitHub</a> /
                    <a href="https://youtu.be/EhMrf4G5Wf0">Video demo</a> /
                    <a href="https://drive.google.com/open?id=0B2fFW2t9-qW3LWFDNXVHUE9rV3M">App APK</a>
                </p>
            </div>
            <img src="figs/yolo.png" alt="android-yolo" class="publication-image">
        </div>
    </body>
    </html>